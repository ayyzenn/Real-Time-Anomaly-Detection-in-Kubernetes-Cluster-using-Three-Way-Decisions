{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a14ac70c-9ec6-4000-a5d5-aa013edffd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "import csv\n",
    "import threading\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.stats import median_abs_deviation\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Prometheus API endpoint\n",
    "prometheus_api = \"http://192.168.49.2:31090/api/v1/query\"\n",
    "\n",
    "# Prometheus query\n",
    "query = \"sum(rate(container_cpu_usage_seconds_total{pod=~\\\"front-end-.*\\\", namespace=\\\"sock-shop\\\"}[1m])) by (pod_name)\"\n",
    "\n",
    "# CSV file path\n",
    "csv_file_path = \"frontend_cpu_data.csv\"\n",
    "\n",
    "# CSV file header\n",
    "csv_header = [\"Timestamp\", \"Value\", \"anomaly\"]\n",
    "\n",
    "# Lock for synchronization\n",
    "lock = threading.Lock()\n",
    "\n",
    "column_name=\"Value\"\n",
    "window_size=5\n",
    "threshold=4\n",
    "\n",
    "def fetch_data():\n",
    "    while True:\n",
    "        # Fetch data from Prometheus\n",
    "        params = {\"query\": query}\n",
    "        response = requests.get(prometheus_api, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        # Open CSV file in append mode\n",
    "        with open(csv_file_path, mode=\"a\", newline=\"\") as csv_file:\n",
    "            writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write header if file is empty\n",
    "            if csv_file.tell() == 0:\n",
    "                writer.writerow(csv_header)\n",
    "\n",
    "            # Write data to CSV\n",
    "            for result in data[\"data\"][\"result\"]:\n",
    "                time = result[\"value\"][0]\n",
    "                dt_object = datetime.datetime.fromtimestamp(time)\n",
    "                timestamp = dt_object.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                value = float(result[\"value\"][1])\n",
    "                rounded_value = round(value, 5)\n",
    "                anomaly=0\n",
    "                writer.writerow([timestamp, rounded_value, anomaly])\n",
    "        \n",
    "        # Sleep for 5 seconds\n",
    "        sleep(5)\n",
    "\n",
    "def detect_anomaly():\n",
    "    while True:\n",
    "        \n",
    "        while not os.path.exists(csv_file_path) or get_csv_row_count() < 5:\n",
    "            sleep(5)\n",
    "\n",
    "         # Read CSV file\n",
    "        data = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        new_data = data[-5:]\n",
    "        \n",
    "\n",
    "        df = pd.read_csv('frontend_cpu_result.csv')\n",
    "        \n",
    "        if df.empty:\n",
    "            data1=sliding_window_std(new_data, column_name, window_size, threshold)\n",
    "            data1.to_csv('frontend_cpu_result.csv', mode='a', index=False, header=False)\n",
    "        else:\n",
    "            last_value = df.iloc[-1]['Time']\n",
    "            time2_dt = datetime.datetime.strptime(str(last_value), '%Y-%m-%d %H:%M:%S')\n",
    "            value= new_data.iloc[0]['Timestamp']\n",
    "            time1_dt = datetime.datetime.strptime(str(value), '%Y-%m-%d %H:%M:%S')\n",
    "            if time1_dt > time2_dt :\n",
    "                data1=sliding_window_std(new_data, column_name, window_size, threshold)\n",
    "                data1.to_csv('frontend_cpu_result.csv', mode='a', index=False, header=False)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # Sleep for 5 seconds\n",
    "    time.sleep(5)\n",
    "    \n",
    "    \n",
    "# Functions for anomaly detection and evaluation\n",
    "def sliding_window_std(df, column_name, window_size, threshold):\n",
    "    results = []\n",
    "    problem_vals = []  # List to store values that exceed the threshold\n",
    "    problematic_rows = []  # List to store rows corresponding to problematic values\n",
    "    for i in range(len(df)):\n",
    "        # Calculate the window boundaries\n",
    "        start_index = df.index[i] \n",
    "        if i < len(df)-window_size:\n",
    "            end_index = window_size + i\n",
    "        else:\n",
    "            end_index=len(df)\n",
    "\n",
    "        \n",
    "        # Get the numbers within the window\n",
    "        window = df[column_name].iloc[start_index:end_index]\n",
    "        \n",
    "        # Calculate the standard deviation of the window\n",
    "        std_dev = window.std()\n",
    "        \n",
    "        # Append the result to the results list\n",
    "        results.append((i, df.iloc[i][column_name], window.tolist(), std_dev))\n",
    "        if len(results) >= 3:\n",
    "            avg_prev_results = (results[-3][3] + results[-2][3]) / 2\n",
    "            threshold_value = avg_prev_results + threshold\n",
    "\n",
    "            if std_dev > threshold_value:\n",
    "                # Append the index and value to problem_vals\n",
    "                row = finding_row_number(df[column_name],  window.iloc[-1])\n",
    "                problematic_row = df.iloc[row]\n",
    "                \n",
    "                if removing_seasonal_points(problematic_row):\n",
    "                    #problem_vals.append((i - window_size // 2, window.iloc[-1]))\n",
    "                    df.at[row, 'anomaly'] = 1\n",
    "                else:\n",
    "                    pass\n",
    "    return df\n",
    "                \n",
    "\n",
    "def finding_row_number(original_lst, anomaly_lst):\n",
    "    i = original_lst.index[0]\n",
    "    for num in original_lst:\n",
    "        if num == anomaly_lst:\n",
    "            return i\n",
    "        i +=1\n",
    "\n",
    "def removing_seasonal_points(anomalous_row):\n",
    "    a=anomalous_row[\"Timestamp\"]\n",
    "    dt_obj = datetime.datetime.strptime(str(a), '%Y-%m-%d %H:%M:%S')\n",
    "    if dt_obj.hour== 0 and  dt_obj.minute== 0:\n",
    "        return False        \n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def get_csv_row_count():\n",
    "    if os.path.exists(csv_file_path):\n",
    "        with open(csv_file_path, mode=\"r\") as csv_file:\n",
    "            reader = csv.reader(csv_file)\n",
    "            row_count = sum(1 for _ in reader)\n",
    "        return row_count\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Start fetch_data thread\n",
    "    fetch_data_thread = threading.Thread(target=fetch_data)\n",
    "    fetch_data_thread.start()\n",
    "\n",
    "    # Start detect_anomaly thread\n",
    "    detect_anomaly_thread = threading.Thread(target=detect_anomaly)\n",
    "    detect_anomaly_thread.start()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2705f5-bf8f-4d49-b98a-370ccffe02cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805245d-31b0-4ca3-80cb-090b44b85834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
