{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967fe5b6-f5f0-4f36-9c41-70c65e1f8b54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636904761904762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Functions for anomaly detection and evaluation\n",
    "\n",
    "def sliding_window_std(df, column_name, window_size, threshold):\n",
    "    results = []\n",
    "    problem_vals = []  # List to store values that exceed the threshold\n",
    "    problematic_rows = []  # List to store rows corresponding to problematic values\n",
    "    j=0\n",
    "    for i in range(len(df)):\n",
    "        # Calculate the window boundaries\n",
    "        start_index = max(0, i - window_size // 2)\n",
    "        end_index = min(len(df), i + window_size // 2 + 1)\n",
    "        \n",
    "        # Get the numbers within the window\n",
    "        window = df[column_name].iloc[start_index:end_index]\n",
    "        \n",
    "        # Calculate the standard deviation of the window\n",
    "        std_dev = window.std()\n",
    "        \n",
    "        # Append the result to the results list\n",
    "        results.append((i, df.iloc[i][column_name], window.tolist(), std_dev))\n",
    "        if len(results) >= 3:\n",
    "            avg_prev_results = (results[-3][3] + results[-2][3]) / 2\n",
    "            threshold_value = avg_prev_results + threshold\n",
    "\n",
    "            if std_dev > threshold_value or std_dev < threshold_value:\n",
    "                # Append the index and value to problem_vals\n",
    "                problem_vals.append((i - window_size // 2, window.iloc[-1]))\n",
    "                # print(problem_vals)\n",
    "                row = finding_row_number(df[column_name], problem_vals)\n",
    "                # print(row)\n",
    "                # print(i) \n",
    "                row_num = row[j][0]\n",
    "                \n",
    "                # print(row_num)\n",
    "                problematic_rows.append(df.iloc[row_num])\n",
    "                j +=1\n",
    "    #print(problematic_rows)\n",
    "    return results, problem_vals #, problematic_rows\n",
    "\n",
    "def actual_anomaly(df):\n",
    "    anomaly_rows = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        if row['anomaly'] == 1:\n",
    "            # Append a tuple containing the row number and the value from the 'anomaly' column to the result list\n",
    "            anomaly_rows.append((i, row['value']))\n",
    "    # print(anomaly_rows)\n",
    "    return anomaly_rows\n",
    "\n",
    "def find_normal_values(original_lst, anomaly_lst):\n",
    "    normal_values = []\n",
    "    for num in original_lst:\n",
    "        is_anomaly = False\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                is_anomaly = True\n",
    "                break\n",
    "        if not is_anomaly:\n",
    "            normal_values.append(num)\n",
    "    return normal_values\n",
    "\n",
    "def finding_row_number(original_lst, anomaly_lst):\n",
    "    rows = []\n",
    "    i = -1\n",
    "    for num in original_lst:\n",
    "        i +=1\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                rows.append((i,num))\n",
    "    return rows\n",
    "\n",
    "def categorize_points(original_lst, anomaly_lst):\n",
    "    normal = []\n",
    "    seasonal = []\n",
    "    anomalies = []\n",
    "\n",
    "    for i, num in enumerate(original_lst):\n",
    "        if num not in (value for _, value in anomaly_lst):\n",
    "            normal.append((i, num))\n",
    "        elif i % 12 == 0 or i % 168 ==0:\n",
    "            seasonal.append((i, num))\n",
    "        else:\n",
    "            anomalies.append((i, num))\n",
    "\n",
    "    return normal, seasonal, anomalies\n",
    "\n",
    "def evaluate_anomaly_detection(true_labels, predicted_labels):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Extract true positives (TP) and true negatives (TN)\n",
    "    TP = cm[1, 1]  # Actual positive (1) and predicted positive (1)\n",
    "    TN = cm[0, 0]  # Actual negative (0) and predicted negative (0)\n",
    "    FP = cm[0, 1]  # Actual negative (0) but predicted positive (1)\n",
    "    FN = cm[1, 0]  # Actual positive (1) but predicted negative (0)\n",
    "\n",
    "    # # Output true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN)\n",
    "    # print(\"True Positives (TP):\", TP)\n",
    "    # print(\"True Negatives (TN):\", TN)\n",
    "    # print(\"False Positives (FP):\", FP)\n",
    "    # print(\"False Negatives (FN):\", FN)\n",
    "\n",
    "    # # Generate classification report\n",
    "    # report = classification_report(true_labels, predicted_labels)\n",
    "    # print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Calculate Recall\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    # print(\"Accuracy:\", accuracy)\n",
    "    # print(\"Precision:\", precision)\n",
    "    # print(\"Recall:\", recall)\n",
    "    # print(\"F1-score:\", f1_score)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "df = pd.read_csv(\"yahoo_data/A4Benchmark/A4Benchmark-TS1.csv\")\n",
    "\n",
    "# Specify the column name containing the data\n",
    "column_name = 'value'\n",
    "\n",
    "window_size = 20\n",
    "threshold = 20  # Adjust threshold as needed\n",
    "std_devs, anomalies = sliding_window_std(df, column_name, window_size, threshold)\n",
    "actual = actual_anomaly(df)\n",
    "normal_values = find_normal_values(df[column_name], anomalies)\n",
    "\n",
    "anomaly_row_list = finding_row_number(df[column_name], anomalies)\n",
    "normal_list, seasonal_anomalies, other_anomalies = categorize_points(df['value'], anomaly_row_list)\n",
    "\n",
    "# Initialize and mark predicted anomalies\n",
    "df['predicted_anomalies'] = 0\n",
    "for anomaly_index, _ in other_anomalies:\n",
    "    df.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "\n",
    "# Evaluate anomaly detection and return accuracy\n",
    "accuracy = evaluate_anomaly_detection(df['anomaly'], df['predicted_anomalies'])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfecf25-5f7c-4253-9b1d-5376a751fbbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
