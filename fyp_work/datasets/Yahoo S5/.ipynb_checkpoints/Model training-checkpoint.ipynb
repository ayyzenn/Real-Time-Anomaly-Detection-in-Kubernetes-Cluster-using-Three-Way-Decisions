{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95936742",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b3f1ee6f",
   "metadata": {},
   "source": [
    "ARIMA & LSTM (Supervised) \n",
    "\n",
    "\n",
    "SVMs & KNN (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb418a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Assuming all CSV files are in the same directory\n",
    "files = glob.glob('./A1Benchmark/*.csv')\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Loop through all CSV files and concatenate the data\n",
    "for file in files:\n",
    "    # Assuming the files have a header, if not, set header=None\n",
    "    data = pd.read_csv(file)\n",
    "    all_data = pd.concat([all_data, data], axis=0)\n",
    "\n",
    "# Resetting the index of the concatenated DataFrame\n",
    "all_data = all_data.reset_index(drop=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_csv('A1Bench_all.csv', sep= ',', index=False , encoding='utf-8')\n",
    "df = pd.read_csv('./A1Bench_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031c2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f6b9a3",
   "metadata": {},
   "source": [
    "# SVMs Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd142af",
   "metadata": {},
   "source": [
    "### SVMs Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv('./file2.csv')\n",
    "# df= pd.read_csv('./A3Benchmark/A3Benchmark-TS1.csv')\n",
    "\n",
    "# Preprocessing\n",
    "scaler = StandardScaler()\n",
    "df[['value', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3']] = scaler.fit_transform(df[['value', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3']])\n",
    "\n",
    "# Define input features and target\n",
    "X = df[['timestamps','value','changepoint', 'trend', 'noise', 'seasonality1', 'seasonality2', 'seasonality3']]\n",
    "y = df['anomaly']\n",
    "\n",
    "# spliting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=40)\n",
    "\n",
    "# training our model\n",
    "clf = SVC(kernel='sigmoid', C=1.0) # rbf , sigmoid\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred, zero_division=np.nan)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08261fad",
   "metadata": {},
   "source": [
    "# One Class SVMs Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cb2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "# Assuming df is your DataFrame\n",
    "# You might need to preprocess your data before using it\n",
    "df = pd.read_csv(\"./A1Benchmark/real_1.csv\")\n",
    "\n",
    "# Drop the \"timestamp\" column as it's not useful for the SVM model\n",
    "df = df.drop(\"timestamp\", axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train one-class SVM model\n",
    "model = OneClassSVM(nu=0.006)  # You may need to tune the nu parameter based on your dataset\n",
    "model.fit(X_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "# Convert predictions to 0 for normal, 1 for anomaly\n",
    "predictions[predictions == 1] = 0\n",
    "predictions[predictions == -1] = 1\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(X_test[\"is_anomaly\"], predictions))\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(X_test[\"is_anomaly\"], predictions)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Normal', 'Anomaly'], yticklabels=['Normal', 'Anomaly'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c453fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Filter out warnings\n",
    "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(\"ignore\", category=TypeError)\n",
    "\n",
    "# Load your undersampled dataset\n",
    "undersampled_df = pd.read_csv('./A1Bench_all.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    undersampled_df.drop('is_anomaly', axis=1),\n",
    "    undersampled_df['is_anomaly'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Filter out only the normal instances (class 0) for training\n",
    "X_train_normal = X_train[y_train == 0]\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {'nu': [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3]}\n",
    "\n",
    "# Create the One-Class SVM model\n",
    "model = OneClassSVM()\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train_normal)\n",
    "\n",
    "# Get the best parameter from the grid search\n",
    "best_nu = grid_search.best_params_['nu']\n",
    "\n",
    "# Create and train the One-Class SVM model with the best parameter\n",
    "final_model = OneClassSVM(nu=best_nu)\n",
    "final_model.fit(X_train_normal)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Convert predictions to 0 for normal instances and 1 for anomalies\n",
    "y_pred[y_pred == 1] = 0  # Predicted normal instances\n",
    "y_pred[y_pred == -1] = 1  # Predicted anomalies\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(y_test, y_pred))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "disp_cm = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp_cm.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046fb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
