{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "# from load_data import *\n",
    "import rpy2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading  Training and Test Data Sets from csv to dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(\"./A1Benchmark/real_23.csv\") #training data set1\n",
    "train_data1=pd.read_csv(\"./A1Benchmark/real_24.csv\")  #training data set2\n",
    "\n",
    "test_data1=pd.read_csv(\"./A1Benchmark/real_18.csv\") #Test data set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting required columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train_data.iloc[:,(1)].values # selecting data values for training set1\n",
    "y_train=train_data.iloc[:,2].values # selecting target class for training set1\n",
    "\n",
    "\n",
    "x_train1=train_data1.iloc[:,(1)].values # selecting data values for training set2\n",
    "y_train1=train_data1.iloc[:,2].values #selecting target class for training set2\n",
    "\n",
    "x_test1=test_data1.iloc[:,(1)].values # selecting data values for test set1\n",
    "y_test1=test_data1.iloc[:,2].values #selecting target class for test set1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping selected dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(-1,1) #reshaping training set 1 because it contains onyl single feature\n",
    "x_train1=x_train1.reshape(-1,1)# reshaping training set 2\n",
    "x_test1=x_test1.reshape(-1,1) #reshaping test set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing the Test and Training data between 0 and 1 // If necessary ////No need now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#x_train1 = min_max_scaler.fit_transform(x_train1) # normalizing training set2\n",
    "#x_test1 = min_max_scaler.fit_transform(x_test1) #normalizing test set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating model for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=linear_model.LinearRegression()\n",
    "clf.fit(x_train,y_train) #training model over training set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Training the generated Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "s = pickle.dumps(clf) #dumping the trained model over set1 into s\n",
    "clf2 = pickle.loads(s) #This model will contain trained data and wil continue the same.\n",
    "clf2.fit(x_train1,y_train1) #Training the Previously generated model over set2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_expect=y_test1\n",
    "y_pred=clf2.predict(x_test1) #calculating predicted value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Function for Rounding off the Predicted Values to 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(i):\n",
    "    if (i > 1.309 and i < 1.5): # Limits set for i after analyzing the Predicted values(y_pred) // for csv 18 and 49\n",
    "        i =1\n",
    "    elif (i < -0.19 or (i > 0.30 and i < 1)): # for csv 53\n",
    "        i=1\n",
    "    else:\n",
    "         i=0\n",
    "    return i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new=np.array([]) # initiating an empty numpy array for storing round off values from y_pred\n",
    "for i in y_pred:\n",
    "    y_pred_new=np.append(y_pred_new,(r(i)))\n",
    "\n",
    "#for i in y_pred_new: #Uncomment this line to see predicted values\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Required libraries for Generating confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=confusion_matrix(y_expect,y_pred_new)\n",
    "print(\"confusion_matrix\")\n",
    "print(\"\\n\",results)\n",
    "print(\"\\n\\n accuracy_score:\",accuracy_score(y_expect,y_pred_new)) # for printing accuracy\n",
    "print('\\n\\n classification report\\n\\n',metrics.classification_report(y_expect,y_pred_new)) # for printing confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of Time-Series Data along with anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_data_anomaly_positions = train_data.loc[train_data['is_anomaly'] == 1,  ('timestamp','value')]\n",
    "test_data_anomaly_positions = test_data1.loc[test_data1['is_anomaly'] == 1,  ('timestamp','value')]\n",
    "fig = plt.figure(1)\n",
    "plt.plot(train_data['timestamp'], train_data['value'], color=\"blue\")\n",
    "plt.title(\"Training Dataset\")\n",
    "plt.plot(train_data_anomaly_positions['timestamp'], train_data_anomaly_positions['value'], 'ro', color=\"red\")\n",
    "\n",
    "fig = plt.figure(2)\n",
    "plt.plot(test_data1['timestamp'], test_data1['value'], color=\"blue\")\n",
    "plt.title(\"Testing Dataset\")\n",
    "plt.plot(test_data_anomaly_positions['timestamp'], test_data_anomaly_positions['value'], 'ro', color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Model for Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\"\"\"\n",
    "    Created on Sep 4\n",
    "    @author : WaVeRiDeR(Atul)\n",
    "\"\"\"\n",
    "\n",
    "print(train_data.head()) #Returns first 5 rows of Train_data\n",
    "print(test_data1.head())  #Returns first 5 rows of Test_data\n",
    "\n",
    "#Returns Descriptive Statistics that summarizes the central Tendency\n",
    "print(train_data.describe())\n",
    "print(test_data1.describe())\n",
    "\n",
    "#Information of a DataFrames\n",
    "print(train_data.info())\n",
    "print(test_data1.info())\n",
    "\n",
    "#Prints the Shape of a DataFrames\n",
    "print(test_data1.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "#Droping of Missing Data\n",
    "#test_data = test_data.dropna()\n",
    "#train_data = train_data.dropna()\n",
    "\n",
    "#Prints the Shape of a DataFrames after droping\n",
    "print(test_data1.shape)\n",
    "print(train_data.shape)\n",
    "\n",
    "#Visualizing Train_data and Test_data\n",
    "sns.jointplot(x = 'timestamp', y = 'value', data = train_data)\n",
    "sns.jointplot(x = 'timestamp', y = 'value', data = test_data1)\n",
    "\n",
    "#Creation of Linear Model Object\n",
    "lm = LinearRegression()\n",
    "\n",
    "#Slicing of Datasets\n",
    "x_train = pd.DataFrame(train_data.iloc[:,0].values)\n",
    "y_train = pd.DataFrame(train_data.iloc[:,1].values)\n",
    "\n",
    "x_test = pd.DataFrame(test_data1.iloc[:,0].values)\n",
    "y_test = pd.DataFrame(test_data1.iloc[:,1].values)\n",
    "\n",
    "#Training the Model by training dataset\n",
    "lm.fit(x_train,y_train)\n",
    "\n",
    "#Prints the Accuracy of Model\n",
    "accuracy = round(lm.score(x_train,y_train) *100,2)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#Prints the Coefficients\n",
    "print('Coefficients', lm.coef_)\n",
    "\n",
    "#Estimated prediction of y_test values based on trained model\n",
    "predictions = lm.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Regression Line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the Training Dataset\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.scatter(x_train,y_train)\n",
    "plt.plot(x_train,lm.predict(x_train), color = 'blue')\n",
    "#plt.xlim(5)\n",
    "#plt.ylim(2)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Training Data')\n",
    "\n",
    "# it is what gives the transparency to the points.\n",
    "# if they suppose themselves, the colors are added.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real Test Values Versus Predicted Test Values\n",
    "plt.scatter(y_test,predictions)\n",
    "plt.xlabel('Y Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('R_values VS P_values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets check the distribution of our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model was correct choice for data because of Normal distribution\n",
    "sns.distplot((y_test-predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(x_train,lm.predict(x_train), color = 'red')\n",
    "plt.figure(figsize = (12,6))\n",
    "cols = np.where(y_train[0]<=0.6,'r','b')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Training Data')\n",
    "plt.scatter(x=x_train,y=y_train,c=cols) #Pass on the list created by the function here\n",
    "plt.plot(x_train,lm.predict(x_train), color = 'black')\n",
    "plt.show()\n",
    "plt.savefig(\"new.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the benchmark files (A2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def apply_styles():\n",
    "    matplotlib.rcParams['font.size'] = 12\n",
    "    matplotlib.rcParams['figure.figsize'] = (18, 6)\n",
    "    matplotlib.rcParams['lines.linewidth'] = 1\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "    plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['axes.labelsize'] = 11\n",
    "    plt.rcParams['axes.labelweight'] = 'bold'\n",
    "    plt.rcParams['axes.titlesize'] = 12\n",
    "    plt.rcParams['xtick.labelsize'] = 9\n",
    "    plt.rcParams['ytick.labelsize'] = 9\n",
    "    plt.rcParams['legend.fontsize'] = 11\n",
    "    plt.rcParams['figure.titlesize'] = 13\n",
    "\n",
    "apply_styles()\n",
    "\n",
    "path='../A2Benchmark/*.csv'\n",
    "Benchmark = []\n",
    "\n",
    "data_load(path, Benchmark)\n",
    "\n",
    "check_null(Benchmark)\n",
    "\n",
    "convert_to_date_time(Benchmark)\n",
    "\n",
    "#set_index_df(Benchmark)\n",
    "\n",
    "count_data_instance(Benchmark)\n",
    "\n",
    "count_anomaly_instances(Benchmark)\n",
    "\n",
    "labelled_anomaly_positions(Benchmark)\n",
    "\n",
    "data_stat(Benchmark)\n",
    "\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Value')\n",
    "plt.title(\"Synthetic_1.csv\")\n",
    "#Benchmark.plot(subplots=True, figsize=(10,12))\n",
    "A2A = plt.plot(Benchmark[0]['timestamp'], Benchmark[0]['value'])\n",
    "plt.savefig('synthetic_1.png')\n",
    "plt.show(A2A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on ARIMA Model.\n",
    "#### ARIMA Model on Yahoo Benchmark Dataset\n",
    "### Adding all the A2 Datasets in One Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A2Apaths = ['./A2Benchmark/synthetic_1.csv', './A2Benchmark/synthetic_2.csv','./A2Benchmark/synthetic_3.csv','./A2Benchmark/synthetic_4.csv','./A2Benchmark/synthetic_5.csv'\n",
    ",'./A2Benchmark/synthetic_6.csv','./A2Benchmark/synthetic_7.csv','./A2Benchmark/synthetic_8.csv','./A2Benchmark/synthetic_9.csv','./A2Benchmark/synthetic_10.csv'\n",
    "          ,'./A2Benchmark/synthetic_10.csv','./A2Benchmark/synthetic_11.csv','./A2Benchmark/synthetic_12.csv','./A2Benchmark/synthetic_13.csv'\n",
    "          ,'./A2Benchmark/synthetic_14.csv','./A2Benchmark/synthetic_15.csv','./A2Benchmark/synthetic_17.csv','./A2Benchmark/synthetic_18.csv','./A2Benchmark/synthetic_19.csv', './A2Benchmark/synthetic_20.csv','./A2Benchmark/synthetic_21.csv','./A2Benchmark/synthetic_22.csv','./A2Benchmark/synthetic_23.csv'\n",
    ",'./A2Benchmark/synthetic_24.csv','./A2Benchmark/synthetic_25.csv','./A2Benchmark/synthetic_26.csv','./A2Benchmark/synthetic_27.csv','./A2Benchmark/synthetic_28.csv','./A2Benchmark/synthetic_29.csv', './A2Benchmark/synthetic_30.csv','./A2Benchmark/synthetic_31.csv','./A2Benchmark/synthetic_32.csv','./A2Benchmark/synthetic_33.csv'\n",
    ",'./A2Benchmark/synthetic_34.csv','./A2Benchmark/synthetic_35.csv','./A2Benchmark/synthetic_36.csv','./A2Benchmark/synthetic_37.csv','./A2Benchmark/synthetic_38.csv','./A2Benchmark/synthetic_39.csv','./A2Benchmark/synthetic_40.csv','./A2Benchmark/synthetic_41.csv'\n",
    "          ,'./A2Benchmark/synthetic_42.csv','./A2Benchmark/synthetic_43.csv','./A2Benchmark/synthetic_44.csv','./A2Benchmark/synthetic_45.csv'\n",
    "          ,'./A2Benchmark/synthetic_46.csv','./A2Benchmark/synthetic_47.csv','./A2Benchmark/synthetic_48.csv', './A2Benchmark/synthetic_49.csv','./A2Benchmark/synthetic_50.csv','./A2Benchmark/synthetic_51.csv','./A2Benchmark/synthetic_52.csv'\n",
    ",'./A2Benchmark/synthetic_53.csv','./A2Benchmark/synthetic_54.csv','./A2Benchmark/synthetic_55.csv','./A2Benchmark/synthetic_56.csv','./A2Benchmark/synthetic_57.csv'\n",
    "          ,'./A2Benchmark/synthetic_58.csv','./A2Benchmark/synthetic_59.csv','./A2Benchmark/synthetic_60.csv','./A2Benchmark/synthetic_61.csv'\n",
    "          ,'./A2Benchmark/synthetic_62.csv','./A2Benchmark/synthetic_63.csv']   \n",
    "df = pd.concat(map(pd.read_csv, A2Apaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many Anomalies are in total of A2 Benchmark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.is_anomaly.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's change the Datetime to readable format for eaasy visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "#A2df.timestamp = A2df.timestamp.dt.tz_localize('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['timestamp'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing required libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use('fivethirtyeight')\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "matplotlib.rcParams['xtick.labelsize'] = 12\n",
    "matplotlib.rcParams['ytick.labelsize'] = 12\n",
    "matplotlib.rcParams['text.color'] = 'k'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a New Dataframe with values and one without values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "newdf = df[['timestamp','value']]\n",
    "newdf['timestamp'] = pd.to_datetime(newdf['timestamp'], unit='s')\n",
    "#newdf.head()\n",
    "\n",
    "#df with anomaly\n",
    "\n",
    "dfano = df[['timestamp','is_anomaly']]\n",
    "dfano['timestamp'] = pd.to_datetime(dfano['timestamp'],unit = 's')\n",
    "dfano.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the starting and ending dates available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf['timestamp'].min(), newdf['timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfano.sort_values('timestamp').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.groupby('timestamp')['value'].sum().reset_index()\n",
    "dfano = dfano.groupby('timestamp')['is_anomaly'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfano.head()\n",
    "#newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = newdf.set_index('timestamp')\n",
    "newdf.index\n",
    "\n",
    "dfano = dfano.set_index('timestamp')\n",
    "dfano.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = newdf['value'].resample('H').median()\n",
    "#y = dfano['is_anomaly'].resample('H').mean()\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(dfano)\n",
    "#print(dfano)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies Present during which time-frame?\n",
    "### As we can see most of the anomalies are present during End of December 2014 and Starting of Jan 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfano.plot(figsize=(15, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Trends and Seasonality of Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of parameter combinations for Seasonal ARIMA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best parameters of ARIMA\n",
    "### The best param so far is ARIMA(1, 1, 1)x(1, 1, 1, 12)12 - AIC:32764.2410727543 \n",
    "#### So we will use this for the forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(y, order=param, seasonal_order=param_seasonal,enforce_stationarity=False, enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(y,\n",
    "                                order=(1, 1, 1),\n",
    "                                seasonal_order=(1, 1, 1, 12),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=pd.to_datetime('2014-12-20'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "ax = y['2014':].plot(label='observed')\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
