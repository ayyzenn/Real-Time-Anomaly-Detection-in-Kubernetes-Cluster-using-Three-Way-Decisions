{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0175bda-c2b3-4845-b482-f634e225c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35fe119d-3146-42c1-82a3-a5f8d8361842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 1\n",
      "True Negatives (TN): 1198\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 2\n",
      "Accuracy: 0.9983347210657785\n",
      "Precision: 1.0\n",
      "Recall: 0.3333333333333333\n",
      "F1-score: 0.5\n",
      "Accuracy for the first half: 0.9983347210657785\n",
      "#####################################################\n",
      "True Positives (TP): 1\n",
      "True Negatives (TN): 458\n",
      "False Positives (FP): 19\n",
      "False Negatives (FN): 1\n",
      "Accuracy: 0.9582463465553236\n",
      "Precision: 0.05\n",
      "Recall: 0.5\n",
      "F1-score: 0.09090909090909091\n",
      "Accuracy for the second half: 0.9582463465553236\n"
     ]
    }
   ],
   "source": [
    "# Functions for anomaly detection and evaluation\n",
    "def sliding_window_std(df, column_name, window_size, threshold):\n",
    "    results = []\n",
    "    problem_vals = []  # List to store values that exceed the threshold\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # Calculate the window boundaries\n",
    "        start_index = max(0, i - window_size // 2)\n",
    "        end_index = min(len(df), i + window_size // 2 + 1)\n",
    "        \n",
    "        # Get the numbers within the window\n",
    "        window = df[column_name].iloc[start_index:end_index]\n",
    "        \n",
    "        # Calculate the standard deviation of the window\n",
    "        std_dev = window.std()\n",
    "        \n",
    "        # Append the result to the results list\n",
    "        # result list conations 3 things (number, window,std of the window)\n",
    "        results.append((i, df.iloc[i][column_name], window.tolist(), std_dev))\n",
    "        # print(results[i],'\\n')\n",
    "\n",
    "        if len(results) <= 2:\n",
    "            # print(\"Skipping iteration#\", i)\n",
    "            # print(\"##################################################\")\n",
    "            continue\n",
    "            \n",
    "        if len(results) >= 3:\n",
    "            # print(\"val1:\",results[-3][3])\n",
    "            # print(\"val2:\",results[-2][3])\n",
    "            # print(\"current std:\",std_dev)\n",
    "            # print(\"current iteration:\", i)\n",
    "            # print(\"##################################################\")\n",
    "\n",
    "            avg_prev_results = (results[-2][3] + results[-3][3]) / 2\n",
    "            threshold_value = avg_prev_results + threshold\n",
    "\n",
    "            if std_dev > threshold_value:\n",
    "                problem_vals.append((i - window_size // 2, window.iloc[-1]))\n",
    "\n",
    "            # print('Problem list:', problem_vals)\n",
    "    return results, problem_vals\n",
    "\n",
    "def actual_anomaly(df):\n",
    "    anomaly_rows = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        if row['anomaly'] == 1:\n",
    "            # Append a tuple containing the row number and the value from the 'anomaly' column to the result list\n",
    "            anomaly_rows.append((i, row['value']))\n",
    "    # print(anomaly_rows)\n",
    "    return anomaly_rows\n",
    "\n",
    "def find_normal_values(original_lst, anomaly_lst):\n",
    "    normal_values = []\n",
    "    for num in original_lst:\n",
    "        is_anomaly = False\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                is_anomaly = True\n",
    "                break\n",
    "        if not is_anomaly:\n",
    "            normal_values.append(num)\n",
    "    return normal_values\n",
    "\n",
    "def finding_row_number(original_lst, anomaly_lst):\n",
    "    rows = []\n",
    "    i = 1\n",
    "    for num in original_lst:\n",
    "        i +=1\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                rows.append((i,num))\n",
    "    return rows\n",
    "\n",
    "def categorize_points(original_lst, anomaly_lst):\n",
    "    normal = []\n",
    "    seasonal = []\n",
    "    anomalies = []\n",
    "\n",
    "    for i, num in enumerate(original_lst):\n",
    "        if num not in (value for _, value in anomaly_lst):\n",
    "            normal.append((i, num))\n",
    "        elif i % 12 == 0 or i % 168 ==0:\n",
    "            seasonal.append((i, num))\n",
    "        else:\n",
    "            anomalies.append((i, num))\n",
    "\n",
    "    return normal, seasonal, anomalies\n",
    "\n",
    "def evaluate_anomaly_detection(true_labels, predicted_labels):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Extract true positives (TP) and true negatives (TN)\n",
    "    TP = cm[1, 1]  # Actual positive (1) and predicted positive (1)\n",
    "    TN = cm[0, 0]  # Actual negative (0) and predicted negative (0)\n",
    "    FP = cm[0, 1]  # Actual negative (0) but predicted positive (1)\n",
    "    FN = cm[1, 0]  # Actual positive (1) but predicted negative (0)\n",
    "\n",
    "    # Output true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN)\n",
    "    print(\"True Positives (TP):\", TP)\n",
    "    print(\"True Negatives (TN):\", TN)\n",
    "    print(\"False Positives (FP):\", FP)\n",
    "    print(\"False Negatives (FN):\", FN)\n",
    "\n",
    "    # # Generate classification report\n",
    "    # report = classification_report(true_labels, predicted_labels)\n",
    "    # print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Calculate Recall\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1_score)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# df = pd.read_csv(\"./dataset/A4Benchmark/A4Benchmark-TS1.csv\")\n",
    "\n",
    "# # Specify the column name containing the data\n",
    "# column_name = 'value'\n",
    "\n",
    "# window_size = 5\n",
    "# threshold = 10  # Adjust threshold as needed\n",
    "# std_devs, anomalies = sliding_window_std(df, column_name, window_size, threshold)\n",
    "# actual = actual_anomaly(df)\n",
    "# normal_values = find_normal_values(df[column_name], anomalies)\n",
    "\n",
    "# anomaly_row_list = finding_row_number(df[column_name], anomalies)\n",
    "# normal_list, seasonal_anomalies, other_anomalies = categorize_points(df['value'], anomaly_row_list)\n",
    "\n",
    "# # Initialize and mark predicted anomalies\n",
    "# df['predicted_anomalies'] = 0\n",
    "# for anomaly_index, _ in other_anomalies:\n",
    "#     df.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "\n",
    "# # Evaluate anomaly detection and return accuracy\n",
    "# accuracy = evaluate_anomaly_detection(df['anomaly'], df['predicted_anomalies'])\n",
    "# print(accuracy)\n",
    "\n",
    "column_name = 'value'\n",
    "\n",
    "window_size = 16\n",
    "threshold = 20  # Adjust threshold as needed\n",
    "\n",
    "# df = pd.read_csv(\"./A4Benchmark/A4Benchmark-TS1.csv\")\n",
    "\n",
    "# Split the DataFrame into two parts\n",
    "first_half = pd.read_csv(\"./A4Benchmark/Train_TS12.csv\")\n",
    "second_half = pd.read_csv(\"./A4Benchmark/Test_TS12.csv\")\n",
    "\n",
    "# Apply anomaly detection on the first half\n",
    "std_devs_first_half, anomalies_first_half = sliding_window_std(first_half, column_name, window_size, threshold)\n",
    "actual_first_half = actual_anomaly(first_half)\n",
    "normal_values_first_half = find_normal_values(first_half[column_name], anomalies_first_half)\n",
    "anomaly_row_list_first_half = finding_row_number(first_half[column_name], anomalies_first_half)\n",
    "normal_list_first_half, seasonal_anomalies_first_half, other_anomalies_first_half = categorize_points(first_half['value'], anomaly_row_list_first_half)\n",
    "\n",
    "# Initialize and mark predicted anomalies for the first half\n",
    "first_half['predicted_anomalies'] = 0\n",
    "for anomaly_index, _ in other_anomalies_first_half:\n",
    "    first_half.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "\n",
    "# Evaluate anomaly detection for the first half\n",
    "accuracy_first_half = evaluate_anomaly_detection(first_half['anomaly'], first_half['predicted_anomalies'])\n",
    "print(\"Accuracy for the first half:\", accuracy_first_half)\n",
    "\n",
    "# Apply anomaly detection on the second half\n",
    "std_devs_second_half, anomalies_second_half = sliding_window_std(second_half, column_name, window_size, threshold)\n",
    "actual_second_half = actual_anomaly(second_half)\n",
    "normal_values_second_half = find_normal_values(second_half[column_name], anomalies_second_half)\n",
    "anomaly_row_list_second_half = finding_row_number(second_half[column_name], anomalies_second_half)\n",
    "normal_list_second_half, seasonal_anomalies_second_half, other_anomalies_second_half = categorize_points(second_half['value'], anomaly_row_list_second_half)\n",
    "\n",
    "# Initialize and mark predicted anomalies for the second half\n",
    "second_half['predicted_anomalies'] = 0\n",
    "for anomaly_index, _ in other_anomalies_second_half:\n",
    "    second_half.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "print('#####################################################')\n",
    "# Drop rows with NaN values from the DataFrame\n",
    "# second_half = second_half.dropna()\n",
    "# Evaluate anomaly detection for the second half\n",
    "accuracy_second_half = evaluate_anomaly_detection(second_half['anomaly'], second_half['predicted_anomalies'])\n",
    "print(\"Accuracy for the second half:\", accuracy_second_half)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f4459-ba27-430d-a010-5e9500baf783",
   "metadata": {},
   "source": [
    "# 2W split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9780b91e-7320-4486-8b8f-91ecb2e4acce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives (TP): 2\n",
      "True Negatives (TN): 1198\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 1\n",
      "Accuracy: 0.9991673605328892\n",
      "Precision: 1.0\n",
      "Recall: 0.6666666666666666\n",
      "F1-score: 0.8\n",
      "Accuracy for the first half: 0.9991673605328892\n",
      "#####################################################\n",
      "True Positives (TP): 2\n",
      "True Negatives (TN): 477\n",
      "False Positives (FP): 0\n",
      "False Negatives (FN): 0\n",
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-score: 1.0\n",
      "Accuracy for the second half: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Functions for anomaly detection and evaluation\n",
    "def sliding_window_std(df, column_name, window_size, threshold):\n",
    "    results = []\n",
    "    problem_vals = []  # List to store values that exceed the threshold\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # Calculate the window boundaries\n",
    "        start_index = max(0, i - window_size // 2)\n",
    "        end_index = min(len(df), i + window_size // 2 + 1)\n",
    "        \n",
    "        # Get the numbers within the window\n",
    "        window = df[column_name].iloc[start_index:end_index]\n",
    "        \n",
    "        # Calculate the standard deviation of the window\n",
    "        std_dev = window.std()\n",
    "        \n",
    "        # Append the result to the results list\n",
    "        # result list conations 3 things (number, window,std of the window)\n",
    "        results.append((i, df.iloc[i][column_name], window.tolist(), std_dev))\n",
    "        # print(results[i],'\\n')\n",
    "\n",
    "        if len(results) <= 2:\n",
    "            # print(\"Skipping iteration#\", i)\n",
    "            # print(\"##################################################\")\n",
    "            continue\n",
    "            \n",
    "        if len(results) >= 3:\n",
    "            # print(\"val1:\",results[-3][3])\n",
    "            # print(\"val2:\",results[-2][3])\n",
    "            # print(\"current std:\",std_dev)\n",
    "            # print(\"current iteration:\", i)\n",
    "            # print(\"##################################################\")\n",
    "\n",
    "            avg_prev_results = (results[-2][3] + results[-3][3]) / 2\n",
    "            threshold_value = avg_prev_results + threshold\n",
    "\n",
    "            if std_dev > threshold_value:\n",
    "                problem_vals.append((i - window_size // 2, window.iloc[-1]))\n",
    "\n",
    "            # print('Problem list:', problem_vals)\n",
    "    return results, problem_vals\n",
    "\n",
    "def actual_anomaly(df):\n",
    "    anomaly_rows = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        if row['anomaly'] == 1:\n",
    "            # Append a tuple containing the row number and the value from the 'anomaly' column to the result list\n",
    "            anomaly_rows.append((i, row['value']))\n",
    "    # print(anomaly_rows)\n",
    "    return anomaly_rows\n",
    "\n",
    "def find_normal_values(original_lst, anomaly_lst):\n",
    "    normal_values = []\n",
    "    for num in original_lst:\n",
    "        is_anomaly = False\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                is_anomaly = True\n",
    "                break\n",
    "        if not is_anomaly:\n",
    "            normal_values.append(num)\n",
    "    return normal_values\n",
    "\n",
    "def finding_row_number(original_lst, anomaly_lst):\n",
    "    rows = []\n",
    "    i = 1\n",
    "    for num in original_lst:\n",
    "        i +=1\n",
    "        for win_num, value in anomaly_lst:\n",
    "            if num == value:\n",
    "                rows.append((i,num))\n",
    "    return rows\n",
    "\n",
    "def categorize_points(original_lst, anomaly_lst):\n",
    "    normal = []\n",
    "    # seasonal = []\n",
    "    anomalies = []\n",
    "\n",
    "    for i, num in enumerate(original_lst):\n",
    "        if num not in (value for _, value in anomaly_lst):\n",
    "            normal.append((i, num))\n",
    "        # elif i % 12 == 0 or i % 168 ==0:\n",
    "        #     seasonal.append((i, num))\n",
    "        else:\n",
    "            anomalies.append((i, num))\n",
    "\n",
    "    return normal, anomalies # , seasonal\n",
    "\n",
    "def evaluate_anomaly_detection(true_labels, predicted_labels):\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    # Extract true positives (TP) and true negatives (TN)\n",
    "    TP = cm[1, 1]  # Actual positive (1) and predicted positive (1)\n",
    "    TN = cm[0, 0]  # Actual negative (0) and predicted negative (0)\n",
    "    FP = cm[0, 1]  # Actual negative (0) but predicted positive (1)\n",
    "    FN = cm[1, 0]  # Actual positive (1) but predicted negative (0)\n",
    "\n",
    "    # Output true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN)\n",
    "    print(\"True Positives (TP):\", TP)\n",
    "    print(\"True Negatives (TN):\", TN)\n",
    "    print(\"False Positives (FP):\", FP)\n",
    "    print(\"False Negatives (FN):\", FN)\n",
    "\n",
    "    # # Generate classification report\n",
    "    # report = classification_report(true_labels, predicted_labels)\n",
    "    # print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    # Calculate Accuracy\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    # Calculate Precision\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Calculate Recall\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Calculate F1-score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1_score)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# df = pd.read_csv(\"./dataset/A4Benchmark/A4Benchmark-TS1.csv\")\n",
    "\n",
    "# # Specify the column name containing the data\n",
    "# column_name = 'value'\n",
    "\n",
    "# window_size = 5\n",
    "# threshold = 10  # Adjust threshold as needed\n",
    "# std_devs, anomalies = sliding_window_std(df, column_name, window_size, threshold)\n",
    "# actual = actual_anomaly(df)\n",
    "# normal_values = find_normal_values(df[column_name], anomalies)\n",
    "\n",
    "# anomaly_row_list = finding_row_number(df[column_name], anomalies)\n",
    "# normal_list, seasonal_anomalies, other_anomalies = categorize_points(df['value'], anomaly_row_list)\n",
    "\n",
    "# # Initialize and mark predicted anomalies\n",
    "# df['predicted_anomalies'] = 0\n",
    "# for anomaly_index, _ in other_anomalies:\n",
    "#     df.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "\n",
    "# # Evaluate anomaly detection and return accuracy\n",
    "# accuracy = evaluate_anomaly_detection(df['anomaly'], df['predicted_anomalies'])\n",
    "# print(accuracy)\n",
    "\n",
    "column_name = 'value'\n",
    "\n",
    "window_size = 14\n",
    "threshold = 16  # Adjust threshold as needed\n",
    "\n",
    "# df = pd.read_csv(\"./A4Benchmark/A4Benchmark-TS1.csv\")\n",
    "\n",
    "# Split the DataFrame into two parts\n",
    "first_half = pd.read_csv(\"./A4Benchmark/Train_TS2.csv\")\n",
    "second_half = pd.read_csv(\"./A4Benchmark/Test_TS2.csv\")\n",
    "\n",
    "# Apply anomaly detection on the first half\n",
    "std_devs_first_half, anomalies_first_half = sliding_window_std(first_half, column_name, window_size, threshold)\n",
    "actual_first_half = actual_anomaly(first_half)\n",
    "normal_values_first_half = find_normal_values(first_half[column_name], anomalies_first_half)\n",
    "anomaly_row_list_first_half = finding_row_number(first_half[column_name], anomalies_first_half)\n",
    "normal_list_first_half, other_anomalies_first_half = categorize_points(first_half['value'], anomaly_row_list_first_half)\n",
    "\n",
    "# Initialize and mark predicted anomalies for the first half\n",
    "first_half['predicted_anomalies'] = 0\n",
    "for anomaly_index, _ in other_anomalies_first_half:\n",
    "    first_half.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "\n",
    "# Evaluate anomaly detection for the first half\n",
    "accuracy_first_half = evaluate_anomaly_detection(first_half['anomaly'], first_half['predicted_anomalies'])\n",
    "print(\"Accuracy for the first half:\", accuracy_first_half)\n",
    "\n",
    "# Apply anomaly detection on the second half\n",
    "std_devs_second_half, anomalies_second_half = sliding_window_std(second_half, column_name, window_size, threshold)\n",
    "actual_second_half = actual_anomaly(second_half)\n",
    "normal_values_second_half = find_normal_values(second_half[column_name], anomalies_second_half)\n",
    "anomaly_row_list_second_half = finding_row_number(second_half[column_name], anomalies_second_half)\n",
    "normal_list_second_half, other_anomalies_second_half = categorize_points(second_half['value'], anomaly_row_list_second_half)\n",
    "\n",
    "# Initialize and mark predicted anomalies for the second half\n",
    "second_half['predicted_anomalies'] = 0\n",
    "for anomaly_index, _ in other_anomalies_second_half:\n",
    "    second_half.at[anomaly_index, 'predicted_anomalies'] = 1\n",
    "print('#####################################################')\n",
    "# Drop rows with NaN values from the DataFrame\n",
    "# second_half = second_half.dropna()\n",
    "# Evaluate anomaly detection for the second half\n",
    "accuracy_second_half = evaluate_anomaly_detection(second_half['anomaly'], second_half['predicted_anomalies'])\n",
    "print(\"Accuracy for the second half:\", accuracy_second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077fa9f-deff-481b-bdc0-94f5e680d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
